{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Name Similarity Degree (10 + 10 + 10 = 30 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Iterative Name Similarity Degree (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def common_char_i(name1,name2):\n",
    "    l = min(len(name1), len(name2))\n",
    "    count = 0\n",
    "    for i in range(l): \n",
    "        if name1.lower()[i] == name2.lower()[i]:\n",
    "            count += 1\n",
    "    return count\n",
    "print(common_char_i('McDonald','Andrey'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Recursive Name Similarity Degree (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def common_char_r(name1,name2):\n",
    "    if not (name1 and name2):\n",
    "        return 0\n",
    "    else:\n",
    "        if name1.lower()[0] == name2.lower()[0]:\n",
    "            return 1 + common_char_r(name1[1:],name2[1:])\n",
    "        else:\n",
    "            return common_char_r(name1[1:],name2[1:])\n",
    "print(common_char_r('Brandy','Flank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 One-liner Name Similarity Degree (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "'''List comprehension approach'''\n",
    "def common_char_u(name1,name2):\n",
    "    return len([1 for i in list(zip(name1.lower(),name2.lower())) if i[0] == i[1]])\n",
    "\n",
    "'''Filter approach'''\n",
    "\n",
    "\n",
    "print(common_char_u('McDonald','Andrey'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Text Compression (20 marksï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_compression(text):\n",
    "    txt_lst = text.split()\n",
    "    low_lst = text.lower().split()\n",
    "    for ind, ele in enumerate(low_lst):\n",
    "        if len(ele)>1:\n",
    "            index_lst = []\n",
    "            for i in range(ind+1, len(low_lst)):\n",
    "                if low_lst[i] == ele:\n",
    "                    index_lst.append(i)\n",
    "                    low_lst[i] = '_'\n",
    "            for i in index_lst:\n",
    "                txt_lst[i] = str(ind + 1)\n",
    "    return ' '.join(txt_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wish me a good morning or mean that it is a 6 7 whether I want not 8 10 2 feel 6 this 7 8 10 11 12 7 to be 6 on\n",
      "Text compression will save the world from inefficiency 8 is a blight on 5 6 and its humanity\n"
     ]
    }
   ],
   "source": [
    "text3 = 'Do you wish me a good morning or mean that it is a good morning whether I want not or that you feel good this morning or that it is morning to be good on'\n",
    "print(text_compression(text3))    \n",
    "text7 = 'Text compression will save the world from inefficiency Inefficiency is a blight on the world and its humanity'\n",
    "print(text_compression(text7))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 ASCII Picture Pattern Matching (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = [[' ', '#', '#', '#', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' '], [' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' '], [' ', '#', '#', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', ' '], [' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', '#', '#', ' '], [' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' '], [' ', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', ' ', ' ', ' ', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', ' ', '#', ' ', ' '], [' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' '], [' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', ' ', ' ', ' ', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', '#', '#', ' '], [' ', '#', ' ', ' ', ' ', ' ', ' ', '#', ' ', '#', '#', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', ' ', ' ', ' ', ' ', '#', ' ', ' ', '#', '#', '#', '#', '#', ' ', ' ', '#', '#', '#', ' ']]\n",
    "pic1 = [['.', '.', '.', '.', '.', '.', '.', '.', '.', '.'], ['.', '.', '#', '.', '#', '.', '.', '.', '.', '.'], ['.', '.', '.', '#', '.', '.', '.', '.', '.', '.'], ['.', '.', '#', '.', '#', '.', '#', '.', '.', '.'], ['.', '.', '.', '.', '.', '#', '.', '.', '.', '.'], ['.', '.', '.', '.', '#', '.', '#', '.', '.', '.'], ['.', '.', '.', '.', '.', '.', '.', '.', '.', '.']]\n",
    "part1 = ['#.#','.#.','#.#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2, 3, 4), (3, 4, 5, 6)]\n"
     ]
    }
   ],
   "source": [
    "def pattern_matching(picture, part):\n",
    "    res = []\n",
    "    rows_pic, cols_pic = len(picture), len(picture[0])\n",
    "    rows_part, cols_part = len(part), len(part[0])\n",
    "\n",
    "    for i in range(rows_pic - rows_part + 1):\n",
    "        for j in range(cols_pic - cols_part + 1):\n",
    "            if all(picture[i + x][j + y] == part[x][y] for x in range(rows_part) for y in range(cols_part)):\n",
    "                res.append((i, j, i + rows_part - 1, j + cols_part - 1))\n",
    "    return res\n",
    "print(pattern_matching(pic1,part1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 War Strategy Prediction (30 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strategic_count(mapfile):\n",
    "    file = open(mapfile, \"r\")\n",
    "    routes = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    routes_ls = [i.strip().split(\" \") for i in routes]\n",
    "    del routes\n",
    "\n",
    "    location_info = dict()\n",
    "\n",
    "    location_index = 0\n",
    "    for route in routes_ls:\n",
    "        location_info[route[0]] = [location_index, -1]\n",
    "        location_index += 1\n",
    "\n",
    "    return dp_retrieve_next(\"CountryA\", location_info, routes_ls)\n",
    "\n",
    "\n",
    "def dp_retrieve_next(start_location, location_info_map, routes_ls):\n",
    "    if start_location == \"capitalB\":\n",
    "        return 1\n",
    "    elif start_location == \"deadend\":\n",
    "        return 0\n",
    "\n",
    "    location_info = location_info_map[start_location]\n",
    "    location_index = location_info[0]\n",
    "    location_next_possibilities = location_info[1]\n",
    "\n",
    "    if location_next_possibilities != -1:\n",
    "        return location_next_possibilities\n",
    "    else:\n",
    "        location_possibilities = 0\n",
    "        for i in range(1, len(routes_ls[location_index])):\n",
    "            next_location_possibilities = dp_retrieve_next(routes_ls[location_index][i],\n",
    "                                                           location_info_map, routes_ls)\n",
    "            location_possibilities += next_location_possibilities\n",
    "        location_info_map[start_location][1] = max(0, location_possibilities)\n",
    "        return location_possibilities\n",
    "\n",
    "\n",
    "strategic_count(\"mapfile2.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
